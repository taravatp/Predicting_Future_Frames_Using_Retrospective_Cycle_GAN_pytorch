{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tdsHNjpxpz8G"},"outputs":[],"source":["!pip install import_ipynb "]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3399,"status":"ok","timestamp":1658558358434,"user":{"displayName":"taravat part","userId":"03908510250861526242"},"user_tz":-270},"id":"AyQroA68OT-v","outputId":"69b8a62e-5d62-4926-e161-5da5c31b03a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1658558358435,"user":{"displayName":"taravat part","userId":"03908510250861526242"},"user_tz":-270},"id":"VCEFiwjFqEVc","outputId":"e00ce1c0-9b15-4ec0-f137-3ee8a6ba4c2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/retrospective cycle GAN\n"]}],"source":["cd /content/drive/MyDrive/retrospective cycle GAN"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"9F6tk0QJbcU8","executionInfo":{"status":"ok","timestamp":1658558358436,"user_tz":-270,"elapsed":20,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","import glob\n","import pickle as pkl\n","import import_ipynb\n","import os\n","\n","from dataset_prepration.Dataset import UCF\n","from models import Generator,Discriminator"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1658558358436,"user":{"displayName":"taravat part","userId":"03908510250861526242"},"user_tz":-270},"id":"BHI2DFuV--5Q","outputId":"fe78c45d-3c40-4694-8a1c-974441006933"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"RdMpxQI4olpM"},"source":["# Defining Dataset"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"w0dLMPDHowbz","executionInfo":{"status":"ok","timestamp":1658558358437,"user_tz":-270,"elapsed":17,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"outputs":[],"source":["train_dataset = UCF(flag = 'train')\n","train_data_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=1) \n","\n","test_dataset = UCF(flag = 'test')\n","test_data_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=1)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1658558358438,"user":{"displayName":"taravat part","userId":"03908510250861526242"},"user_tz":-270},"id":"Hvau4dk6Pu53","outputId":"5fb9647c-1f12-4dcb-a03a-61655d17ec4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["train data: 3844\n","test data: 962\n"]}],"source":["print('train data:',len(train_dataset))\n","print('test data:',len(test_dataset))"]},{"cell_type":"markdown","metadata":{"id":"Pgc6TkeuojAC"},"source":["# Defining Models"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"-fvoV6_NszdR","executionInfo":{"status":"ok","timestamp":1658558359443,"user_tz":-270,"elapsed":8,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"outputs":[],"source":["generator = Generator(12).to(device)\n","frame_discriminator  = Discriminator(3).to(device)\n","sequence_discriminator = Discriminator(15).to(device)"]},{"cell_type":"markdown","metadata":{"id":"RI-DplISop9k"},"source":["# Setting HyperParameters"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"5I8nFLE9s3ls","executionInfo":{"status":"ok","timestamp":1658558365179,"user_tz":-270,"elapsed":4,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"outputs":[],"source":["lambda1, lambda2, lambda3 = 0.005,0.003,0.003\n","beta1, beta2 = 0.5,0.999\n","learning_rate = 0.0003\n","epochs = 10"]},{"cell_type":"markdown","metadata":{"id":"obMeDVsv9pXr"},"source":["# Defining Loss Functions and Optimizers"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"GlRgQoXs9uzu","executionInfo":{"status":"ok","timestamp":1658558367629,"user_tz":-270,"elapsed":3,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"outputs":[],"source":["generator_params = [p for p in generator.parameters() if p.requires_grad]\n","fdiscriminator_params = [p for p in frame_discriminator.parameters() if p.requires_grad]\n","sdiscriminator_params = [p for p in sequence_discriminator.parameters() if p.requires_grad]\n","\n","generator_optimizer = torch.optim.Adam(lr=learning_rate, betas=(beta1, beta2), params=generator_params)\n","frame_discriminator_oprimizer = torch.optim.Adam(lr=learning_rate, betas=(beta1, beta2), params=fdiscriminator_params)\n","sequence_discriminator_optimizer = torch.optim.Adam(lr=learning_rate, betas=(beta1, beta2), params=sdiscriminator_params)"]},{"cell_type":"code","source":["scheduler = torch.optim.lr_scheduler.StepLR(generator_optimizer, step_size=20, gamma=0.1)"],"metadata":{"id":"CIg0aSoMt5tV","executionInfo":{"status":"ok","timestamp":1658558368357,"user_tz":-270,"elapsed":4,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","execution_count":32,"metadata":{"id":"tlf55VNV1tPI","executionInfo":{"status":"ok","timestamp":1658558369995,"user_tz":-270,"elapsed":10,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"outputs":[],"source":["discriminator_loss_function = nn.MSELoss()\n","generator_loss_function = nn.L1Loss()\n","\n","def discriminator_adversarial_loss(real,fake):\n","  real = torch.squeeze(real)\n","  fake = torch.squeeze(fake)\n","  loss = (discriminator_loss_function(real,torch.ones_like(real)) + discriminator_loss_function(fake,torch.zeros_like(fake))) * 0.5\n","  return loss\n","\n","def generator_adversarial_loss(fake):\n","  loss = discriminator_loss_function(fake, torch.ones_like(fake))\n","  return loss\n","\n","def image_similarity(model_output,target):\n","  model_output = torch.squeeze(model_output)\n","  target = torch.squeeze(target)\n","  loss = generator_loss_function(model_output,target)\n","  return loss\n","\n","def image_similarity_LOG(model_output,target):\n","  model_output = LOG(torch.squeeze(model_output))\n","  target = LOG(torch.squeeze(target))\n","\n","  model_output.requires_grad=True\n","  loss = generator_loss_function(model_output,target)\n","  return loss\n","\n","def LOG(image):\n","  image = (image+1) * 127.5\n","  image = image.detach().cpu().numpy().astype(np.uint8)\n","\n","  image = cv2.GaussianBlur(image, (3,3), 0)\n","  image = cv2.Laplacian(image, cv2.CV_64F)\n","  image = torch.tensor(image).to(device)\n","  image = (image/127.5) -1\n","\n","  return image"]},{"cell_type":"code","source":["def reverse(images):\n","  images = images.detach().cpu()\n","  num_channels = 3\n","  num_images = images.shape[1] // 3\n","\n","  all_images = []\n","  for i in range(num_images):\n","    all_images.append(images[:,i*3:(i*3)+3,:,:])\n","  all_images.reverse()\n","\n","  reversed_images = None\n","  for image in all_images:\n","    if reversed_images is None:\n","      reversed_images = image\n","    else:\n","      reversed_images = np.concatenate((reversed_images,image),axis=1)\n","  \n","  reversed_images = torch.tensor(reversed_images).to(device)\n","  return reversed_images"],"metadata":{"id":"3__Nnzg3C-kx","executionInfo":{"status":"ok","timestamp":1658558369996,"user_tz":-270,"elapsed":8,"user":{"displayName":"taravat part","userId":"03908510250861526242"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9SSWythyjzF"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJjkWBN2x4Ul","outputId":"18250f97-48c3-481b-8788-12a74815ee97"},"outputs":[{"output_type":"stream","name":"stdout","text":["finished epoch: 0\n","Frame Discriminator Loss: 0.0018079738438132272 *** Sequence Discriminator Loss: 0.00269393568342252\n","generation reconstruction loss:0.11462849890667866 *** generation LOG loss: 0.03569231198369961 \n","Loss generator: 0.6888417627995844\n","************************************************************\n"]}],"source":["loss_frame_discriminator_over_epochs = [] \n","loss_sequence_discriminator_over_epochs = [] \n","loss_generator_over_epochs = [] \n","loss_generator_similarity_over_epochs = []\n","loss_generator_LOG_similarity_over_epochs = []\n","\n","for epoch in range(epochs):\n","  loss_frame_discriminator_epoch = 0\n","  loss_sequence_discriminator_epoch = 0\n","  loss_generator_epoch = 0\n","  loss_generator_similarity_epoch = 0\n","  loss_generator_LOG_similarity_epoch = 0\n","\n","  for iter,images in enumerate(train_data_loader):\n","    \n","    images = images.to(device)\n","    xm_to_xn = images[:,0:12,:,:] #input \n","    xn_plus_one = images[:,12:15,:,:] #target \n","    xn_plus_one_dash = generator(xm_to_xn) #prediction\n","\n","    xm_plus_one_to_xn_plus_ones = images[:,3:15,:,:] #input \n","    xm_plus_one_to_xn_plus_ones = reverse(xm_plus_one_to_xn_plus_ones)\n","    xm = images[:,0:3,:,:] #target\n","    xm_dash = generator(xm_plus_one_to_xn_plus_ones) #prediction\n","\n","    xm_plus_one_to_xn_plus_one_dash = torch.cat((images[:,3:12,:,:],xn_plus_one_dash.detach()),dim=1)\n","    xm_plus_one_to_xn_plus_one_dash = reverse(xm_plus_one_to_xn_plus_one_dash)\n","    xm_double_dash = generator(xm_plus_one_to_xn_plus_one_dash)\n","\n","    xm_dash_to_xn = torch.cat((xm_dash.detach(),images[:,3:12,:,:]),dim=1)\n","    xn_plus_one_double_dash = generator(xm_dash_to_xn)\n","\n","\n","    #********************training the frame discriminator********************\n","    frame_discriminator_oprimizer.zero_grad()\n","\n","    fake_logits_xn_plus_one_dash = frame_discriminator(xn_plus_one_dash.detach())\n","    fake_logits_xn_plus_one_double_dash = frame_discriminator(xn_plus_one_double_dash.detach())\n","    fake_logits_xm_dash = frame_discriminator(xm_dash.detach())\n","    fake_logits_xm_double_dash = frame_discriminator(xm_double_dash.detach())\n","\n","    real_logits_xn = frame_discriminator(xn_plus_one.detach())\n","    fake_logits_xm = frame_discriminator(xm.detach())\n","\n","    loss_frame_discriminator = discriminator_adversarial_loss(real_logits_xn,fake_logits_xn_plus_one_dash)\n","    loss_frame_discriminator += discriminator_adversarial_loss(real_logits_xn,fake_logits_xn_plus_one_double_dash)\n","    loss_frame_discriminator += discriminator_adversarial_loss(fake_logits_xm,fake_logits_xm_dash)\n","    loss_frame_discriminator += discriminator_adversarial_loss(fake_logits_xm,fake_logits_xm_double_dash)\n","    loss_frame_discriminator = loss_frame_discriminator * lambda2\n","\n","    loss_frame_discriminator_epoch += loss_frame_discriminator.item() #just saving it\n","    loss_frame_discriminator.backward()\n","    frame_discriminator_oprimizer.step()\n","\n","    # it is important to detach the fake data or else training will not work. on detaching, we are creating a fresh copy of the tensor so that when backward is called on the other network, the tensores associated with the other network are not effected!\n","    #********************training the frame discriminator********************\n","\n","    forward_real = images\n","    backward_real = reverse(images)\n","    seq2 = torch.cat((xm_plus_one_to_xn_plus_ones,xm_dash),dim=1) #backward fake\n","    seq3 = torch.cat((images[:,0:12,:,:],xn_plus_one_dash),dim=1) #full forward fake\n","    seq4 = torch.cat((xm_plus_one_to_xn_plus_ones,xm_double_dash),dim=1) #backward fake\n","    seq5 = torch.cat((images[:,0:12,:,:],xn_plus_one_double_dash),dim=1) #full forward fake\n","\n","    #********************training the sequence discriminator********************\n","    sequence_discriminator_optimizer.zero_grad()\n","\n","    real_logits_forward = sequence_discriminator(forward_real)\n","    real_logits_backward = sequence_discriminator(backward_real)\n","\n","    fake_logits = sequence_discriminator(seq3.detach())\n","    loss_sequence_discriminator =  discriminator_adversarial_loss(real_logits_forward,fake_logits)\n","    fake_logits = sequence_discriminator(seq5.detach())\n","    loss_sequence_discriminator +=  discriminator_adversarial_loss(real_logits_forward,fake_logits)\n","    fake_logits = sequence_discriminator(seq2.detach())\n","    loss_sequence_discriminator +=  discriminator_adversarial_loss(real_logits_backward,fake_logits)\n","    fake_logits = sequence_discriminator(seq4.detach())\n","    loss_sequence_discriminator +=  discriminator_adversarial_loss(real_logits_backward,fake_logits)\n","\n","    loss_sequence_discriminator = loss_sequence_discriminator * lambda3\n","    loss_sequence_discriminator_epoch += loss_sequence_discriminator.item() #just saving it\n","    loss_sequence_discriminator.backward()\n","    sequence_discriminator_optimizer.step()\n","    #********************training the sequence discriminator********************\n","    \n","\n","    #********************training the generator********************\n","    generator_optimizer.zero_grad()\n","\n","    #calculating similarity losses\n","    generator_loss_image_similarity = image_similarity(xm_dash,xm) \n","    generator_loss_image_similarity += image_similarity(xm_double_dash,xm)\n","    generator_loss_image_similarity += image_similarity(xm_double_dash,xm_dash.detach())\n","    generator_loss_image_similarity += image_similarity(xn_plus_one_dash,xn_plus_one)\n","    generator_loss_image_similarity += image_similarity(xn_plus_one_double_dash,xn_plus_one)\n","    generator_loss_image_similarity += image_similarity(xn_plus_one_double_dash,xn_plus_one_dash.detach())\n","\n","    #calculating similarity losses on LOG images\n","\n","    generator_loss_LOG_image_similarity = image_similarity_LOG(xm_dash,xm) \n","    generator_loss_LOG_image_similarity += image_similarity_LOG(xm_double_dash,xm)\n","    generator_loss_LOG_image_similarity += image_similarity_LOG(xm_double_dash,xm_dash.detach())\n","    generator_loss_LOG_image_similarity += image_similarity_LOG(xn_plus_one_dash,xn_plus_one) \n","    generator_loss_LOG_image_similarity += image_similarity_LOG(xn_plus_one_double_dash,xn_plus_one) \n","    generator_loss_LOG_image_similarity += image_similarity_LOG(xn_plus_one_double_dash,xn_plus_one_dash.detach())\n","\n","    loss_generator = generator_loss_image_similarity + (lambda1 * generator_loss_LOG_image_similarity)\n","    loss_generator.backward()\n","    generator_optimizer.step()\n","\n","    loss_generator_similarity_epoch += generator_loss_image_similarity.item()/6 #just saving it\n","    loss_generator_LOG_similarity_epoch += generator_loss_LOG_image_similarity.item()/6 #just saving it\n","    loss_generator_epoch += loss_generator.item() #just saving it\n","\n","    #********************training the generator********************\n","  scheduler.step()\n","  print(f\"finished epoch: {epoch}\")\n","\n","  loss_frame_discriminator_over_epochs.append(loss_frame_discriminator_epoch/len(train_data_loader))\n","  loss_sequence_discriminator_over_epochs.append(loss_sequence_discriminator_epoch/len(train_data_loader))\n","  loss_generator_over_epochs.append(loss_generator_epoch/len(train_data_loader))\n","\n","  loss_generator_similarity_over_epochs.append(loss_generator_similarity_epoch/len(train_data_loader))\n","  loss_generator_LOG_similarity_over_epochs.append(loss_generator_LOG_similarity_epoch/len(train_data_loader))\n","\n","  print(f\"Frame Discriminator Loss: {loss_frame_discriminator_epoch/len(train_data_loader)} *** Sequence Discriminator Loss: {loss_sequence_discriminator_epoch/len(train_data_loader)}\")\n","  print(f\"generation reconstruction loss:{loss_generator_similarity_epoch/len(train_data_loader)} *** generation LOG loss: {loss_generator_LOG_similarity_epoch/len(train_data_loader)} \")\n","  print(f\"Loss generator: {loss_generator_epoch/len(train_data_loader)}\")\n","  print(\"************************************************************\")\n","\n","  torch.save(generator.state_dict(), os.path.join('/content/drive/MyDrive/retrospective cycle GAN/trained_models/',f\"Generator{epoch}.pth\"))\n","  torch.save(frame_discriminator.state_dict(), os.path.join('/content/drive/MyDrive/retrospective cycle GAN/trained_models/',f\"frame_discriminator{epoch}.pth\"))\n","  torch.save(sequence_discriminator.state_dict(), os.path.join('/content/drive/MyDrive/retrospective cycle GAN/trained_models/',f\"sequence_discriminator{epoch}.pth\"))\n","\n"]},{"cell_type":"markdown","source":["# Plotting results"],"metadata":{"id":"IxCrs8F-9rzc"}},{"cell_type":"code","source":["fig = plt.figure(1, figsize=(15,10))\n","\n","plt.subplot(2,3,1)\n","plt.plot(loss_frame_discriminator_over_epochs)\n","plt.title('Frame Discriminator Loss over Epoches')\n","                     \n","plt.subplot(2,3,2)\n","plt.plot(loss_sequence_discriminator_over_epochs)\n","plt.title('Sequence Discriminator Loss over Epoches')\n","\n","plt.subplot(2,3,3)\n","plt.plot(loss_generator_over_epochs)\n","plt.title('over all generator Loss over Epoches')\n","\n","plt.subplot(2,3,4)\n","plt.plot(loss_generator_similarity_over_epochs)\n","plt.title('L1-image similarity Loss over Epoches')\n","\n","plt.subplot(2,3,5)\n","plt.plot(loss_generator_LOG_similarity_over_epochs)\n","plt.title('L1-LOG similarity Loss over Epoches')\n","plt.show()"],"metadata":{"id":"Gk6lirEsDNjK"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"main.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}